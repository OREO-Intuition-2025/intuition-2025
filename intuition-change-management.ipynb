{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30918,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import requests\nfrom bs4 import BeautifulSoup\nimport pandas as pd\nimport re\nfrom googlesearch import search\nfrom collections import defaultdict\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.metrics.pairwise import cosine_similarity\n\ndef search_urls(query):\n    urls = []\n    try:\n        for url in search(query,num =10):\n            urls.append(url)\n    except Exception as e:\n        print(f\"Error during Google search: {e}\")\n    return urls\n\ndef scrape_content(url):\n    try:\n        response = requests.get(url)\n        soup = BeautifulSoup(response.content, \"html.parser\")\n        paragraphs = soup.find_all(\"p\")\n        content = \" \".join([para.get_text() for para in paragraphs])\n        content = re.sub(r\"\\s+\", \" \", content)\n        return content.strip()\n    except Exception as e:\n        print(f\"Error scraping {url}: {e}\")\n        return \"\"\n\ndef analyze_text(text, model_name):\n    factors = ['urgency', 'complexity', 'resistance', 'change_level']\n    factor_keywords = {\n        'urgency': ['immediate', 'urgent', 'critical', 'priority'],\n        'complexity': ['complex', 'difficult', 'challenging', 'multifaceted'],\n        'resistance': ['resistance', 'opposition', 'pushback', 'reluctance'],\n        'change_level': ['organization-wide', 'departmental', 'team-level']\n    }\n    \n    scores = {}\n    for factor, keywords in factor_keywords.items():\n        factor_score = sum(text.lower().count(word) for word in keywords)\n        scores[factor] = factor_score\n    \n    total_score = sum(scores.values())\n    if total_score > 0:\n        normalized_scores = {f\"{model_name}_{factor}\": score / total_score \n                             for factor, score in scores.items()}\n    else:\n        normalized_scores = {f\"{model_name}_{factor}\": 0 for factor in factors}\n    \n    return normalized_scores\n\ndef calculate_model_efficiency(all_text, models):\n    vectorizer = TfidfVectorizer()\n    tfidf_matrix = vectorizer.fit_transform([all_text])\n    \n    model_efficiencies = {}\n    for model in models:\n        model_query = vectorizer.transform([model])\n        relevance_score = cosine_similarity(model_query, tfidf_matrix)[0][0]\n        model_text = re.findall(f\"(?i){model}.*?(?=\\n\\n|\\Z)\", all_text, re.DOTALL)\n        model_text = \" \".join(model_text)\n        \n        factor_scores = analyze_text(model_text, model)\n        factor_scores = {k: v * relevance_score for k, v in factor_scores.items()}\n        model_efficiencies.update(factor_scores)\n    \n    return model_efficiencies\n\ndef main_pipeline(change_strategies):\n    all_text = \"\"\n    model_efficiencies = defaultdict(lambda: defaultdict(float))\n    \n    for strategy in change_strategies:\n        print(f\"\\nAnalyzing {strategy}...\")\n        urls = search_urls(f\"{strategy} change management:google scholar\")\n        \n        for url in urls:\n            print(f\"Scraping {url}...\")\n            content = scrape_content(url)\n            all_text += content + \"\\n\\n\"\n        \n        efficiencies = calculate_model_efficiency(all_text, change_strategies)\n        \n        for key, value in efficiencies.items():\n            model, factor = key.split('_', 1)\n            model_efficiencies[model][factor] += value\n    \n    # Normalize the accumulated scores\n    for model in model_efficiencies:\n        total = sum(model_efficiencies[model].values())\n        if total > 0:\n            model_efficiencies[model] = {k: v/total for k, v in model_efficiencies[model].items()}\n    \n    return pd.DataFrame(model_efficiencies).T\n\n# Run the pipeline for specific change management models\nif __name__ == \"__main__\":\n    change_strategies = [\"Lewin's Change Model\", \"McKinsey 7S\"]\n    #change_strategies = [\"ADKAR\", \"Kotter's 8-Step\"]\n    \n    efficiency_df = main_pipeline(change_strategies)\n    \n    print(\"\\nCalculated Model Efficiencies:\")\n    print(efficiency_df)\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import requests\nfrom bs4 import BeautifulSoup\nimport pandas as pd\nimport re\nfrom googlesearch import search\nfrom collections import defaultdict\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.metrics.pairwise import cosine_similarity\n\n# Updated keyword structure with extremes and midpoints\nFACTOR_KEYWORDS = {\n    'urgency': {\n        'low': ['long-term', 'gradual', 'phased', 'incremental'],\n        'medium': ['managed', 'planned', 'scheduled', 'moderate'],\n        'high': ['urgent', 'immediate', 'critical', 'priority']\n    },\n    'complexity': {\n        'low': ['simple', 'basic', 'straightforward', 'routine'],\n        'medium': ['moderate', 'structured', 'organized', 'manageable'],\n        'high': ['complex', 'challenging', 'multifaceted', 'difficult']\n    },\n    'resistance': {\n        'low': ['acceptance', 'support', 'adoption', 'welcome'],\n        'medium': ['neutral', 'mixed', 'varied', 'conditional'],\n        'high': ['resistance', 'opposition', 'pushback', 'reluctance']\n    },\n    'change_level': {\n        'low': ['individual', 'personal', 'role-specific', 'task-level'],\n        'medium': ['departmental', 'team-level', 'group', 'unit'],\n        'high': ['organization-wide', 'enterprise', 'cross-functional', 'strategic']\n    }\n}\n\ndef search_urls(query):\n    urls = []\n    try:\n        for url in search(query,num =10):\n            urls.append(url)\n    except Exception as e:\n        print(f\"Error during Google search: {e}\")\n    return urls\n\ndef scrape_content(url):\n    try:\n        response = requests.get(url)\n        soup = BeautifulSoup(response.content, \"html.parser\")\n        paragraphs = soup.find_all(\"p\")\n        content = \" \".join([para.get_text() for para in paragraphs])\n        content = re.sub(r\"\\s+\", \" \", content)\n        return content.strip()\n    except Exception as e:\n        print(f\"Error scraping {url}: {e}\")\n        return \"\"\n\n\ndef analyze_text(text, model_name):\n    factor_scores = {}\n    \n    for factor, levels in FACTOR_KEYWORDS.items():\n        # Count occurrences for each level\n        counts = {\n            'low': sum(text.lower().count(word) for word in levels['low']),\n            'medium': sum(text.lower().count(word) for word in levels['medium']),\n            'high': sum(text.lower().count(word) for word in levels['high'])\n        }\n        \n        total = sum(counts.values())\n        if total > 0:\n            # Calculate weighted score (low: 0, medium: 0.5, high: 1)\n            weighted_score = (\n                counts['low'] * 0.1 + \n                counts['medium'] * 0.5 + \n                counts['high'] * 0.\n            ) / total\n        else:\n            weighted_score = 0\n            \n        factor_scores[f\"{model_name}_{factor}\"] = weighted_score\n    \n    return factor_scores\n\ndef calculate_model_efficiency(all_text, models):\n    vectorizer = TfidfVectorizer()\n    tfidf_matrix = vectorizer.fit_transform([all_text])\n    \n    model_efficiencies = {}\n    for model in models:\n        model_query = vectorizer.transform([model])\n        relevance_score = cosine_similarity(model_query, tfidf_matrix)[0][0]\n        \n        # Find model-specific content\n        model_text = re.findall(fr\"(?i){re.escape(model)}.*?(?=\\n\\n|\\Z)\", all_text, re.DOTALL)\n        model_text = \" \".join(model_text)\n        \n        # Get factor scores and weight by relevance\n        raw_scores = analyze_text(model_text, model)\n        weighted_scores = {k: v * relevance_score for k, v in raw_scores.items()}\n        model_efficiencies.update(weighted_scores)\n    \n    return model_efficiencies\n\n# (Rest of the code remains the same as in your original implementation)\ndef main_pipeline(change_strategies):\n    all_text = \"\"\n    model_efficiencies = defaultdict(lambda: defaultdict(float))\n    \n    for strategy in change_strategies:\n        print(f\"\\nAnalyzing {strategy}...\")\n        urls = search_urls(f\"{strategy} change management strategy models:google scholar\")\n        \n        for url in urls:\n            print(f\"Scraping {url}\")\n            content = scrape_content(url)\n            all_text += content + \"\\n\\n\"\n        \n        efficiencies = calculate_model_efficiency(all_text, change_strategies)\n        \n        for key, value in efficiencies.items():\n            model, factor = key.split('_', 1)\n            model_efficiencies[model][factor] += value\n    \n    # Normalize the accumulated scores\n    for model in model_efficiencies:\n        total = sum(model_efficiencies[model].values())\n        if total > 0:\n            model_efficiencies[model] = {k: v/total for k, v in model_efficiencies[model].items()}\n    \n    return pd.DataFrame(model_efficiencies).T\nif __name__ == \"__main__\":\n    change_strategies = [\"Lewin's Change Model\", \"McKinsey 7S\", \"Kotter's 8-Step\", \"ADKAR\"]\n    \n    efficiency_df = main_pipeline(change_strategies)\n    \n    print(\"\\nEnhanced Model Analysis:\")\n    print(efficiency_df)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import requests\nfrom bs4 import BeautifulSoup\nimport re\nfrom googlesearch import search\nimport numpy as np\nfrom sentence_transformers import SentenceTransformer, util\n\n# Initialize sentence transformer model\nmodel = SentenceTransformer('all-MiniLM-L6-v2')\n\nMODEL_COEFFICIENTS = {\n    \"Lewin\": {'urgency': 0.267402, 'complexity': 0.312645, 'resistance': 0.169246, 'change_level': 0.250708},\n    \"McKinsey 7S\": {'urgency': 0.353329, 'complexity': 0.215851, 'resistance': 0.161507, 'change_level': 0.269313},\n    \"Kotter\": {'urgency': 0.326516, 'complexity': 0.298532, 'resistance': 0.187739, 'change_level': 0.187214},\n    \"ADKAR\": {'urgency': 0.347329, 'complexity': 0.302746, 'resistance': 0.195419, 'change_level': 0.154505}\n}\n\nFACTOR_PHRASES = {\n    'urgency': [\n        (\"critical emergency\", 2.0), \n        (\"immediate action required\", 1.8),\n        (\"time-sensitive priority\", 1.5)\n    ],\n    'complexity': [\n        (\"system integration challenges\", 2.2),\n        (\"multidisciplinary technical complexity\", 2.0),\n        (\"workflow disruption risks\", 1.7)\n    ],\n    'resistance': [\n        (\"employee apprehension\", 2.1),\n        (\"active change opposition\", 2.0),\n        (\"skill gap concerns\", 1.9)\n    ]\n}\n\ndef generate_search_queries(role, change):\n    \"\"\"Generate simplified search queries\"\"\"\n    return [\n        f\"{change} {role} site:linkedin.com\",\n        f\"{change} {role} filetype:pdf\",\n        f\"{change} workforce resistance site:academia.edu\",\n        f\"{role} change management best practices {change}\",\n        f\"{change} implementation complexity\",\n        f\"{role} team {change} urgency\"\n    ]\n\ndef scrape_content(url):\n    try:\n        response = requests.get(url, timeout=10)\n        soup = BeautifulSoup(response.content, \"html.parser\")\n        paragraphs = soup.find_all(['p', 'article', 'section'])\n        content = \" \".join([p.get_text() for p in paragraphs])\n        return re.sub(r'\\s+', ' ', content).strip()\n    except Exception as e:\n        print(f\"Error scraping {url}: {e}\")\n        return \"\"\n\ndef analyze_factors(text):\n    \"\"\"Enhanced factor scoring with non-linear amplification\"\"\"\n    factor_scores = {}\n    text_embedding = model.encode(text)\n    \n    for factor, phrases in FACTOR_PHRASES.items():\n        max_score = 0\n        for phrase, weight in phrases:\n            phrase_embed = model.encode(phrase)\n            similarity = util.pytorch_cos_sim(text_embedding, phrase_embed).item()\n            amplified_score = (similarity ** 2) * weight\n            if amplified_score > max_score:\n                max_score = amplified_score\n                \n        factor_scores[factor] = 1 / (1 + np.exp(-max_score*3))\n    \n    return factor_scores\n\ndef get_contextual_scores(user_input):\n    \"\"\"Main analysis pipeline with error handling\"\"\"\n    role, change = user_input.split(\"Change:\")[0].replace(\"Role: \", \"\").strip(), user_input.split(\"Change:\")[1].strip()\n    queries = generate_search_queries(role, change)\n    \n    all_text = \"\"\n    for query in queries:\n        try:\n            # Remove advanced parameter and use standard search\n            for url in search(query, num = 3):\n                content = scrape_content(url)\n                print(url)\n                if content:\n                    all_text += content + \"\\n\\n\"\n        except Exception as e:\n            print(f\"Search error for '{query}': {str(e)}\")\n    \n    return analyze_factors(all_text[:10000])\n\ndef recommend_model(user_input, change_level_value=0.2):\n    \"\"\"Enhanced scoring with non-linear amplification\"\"\"\n    factor_scores = get_contextual_scores(user_input)\n    \n    model_scores = {}\n    for model, coeffs in MODEL_COEFFICIENTS.items():\n        score = (\n            (factor_scores['urgency']**2 * coeffs['urgency']) +\n            (factor_scores['complexity']**1.5 * coeffs['complexity']) +\n            (factor_scores['resistance']**1.8 * coeffs['resistance']) +\n            (change_level_value**1.2 * coeffs['change_level'])\n        )\n        model_scores[model] = score\n    \n    return {\n        \"factor_scores\": factor_scores,\n        \"recommendation\": max(model_scores, key=model_scores.get),\n        \"model_scores\": {k: round(v, 3) for k, v in model_scores.items()}\n    }\n\nif __name__ == \"__main__\":\n    user_input = \"Role: Electrical engineer working in the robotics team. Change: AI in the robotics project.\"\n    result = recommend_model(user_input)\n\n    print(\"Factor Scores (0-1 scale):\")\n    for factor, score in result['factor_scores'].items():\n        print(f\"{factor.capitalize()}: {score:.2f}\")\n\n    print(\"\\nRecommended Model:\", result['recommendation'])\n    print(\"\\nModel Scores:\")\n    for model, score in result['model_scores'].items():\n        print(f\"{model}: {score:.2f}\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\nfrom sklearn.model_selection import train_test_split\nimport torch\nfrom kaggle.api.kaggle_api_extended import KaggleApi\n\n# Step 1: Data Collection from Kaggle\napi = KaggleApi()\napi.authenticate()\n\n# Download relevant datasets\napi.dataset_download_files('arashnic/hr-analytics-job-change-of-data-scientists', path='data/', unzip=True)\napi.dataset_download_files('gladdenme/factory-workers-daily-performance-attrition-s', path='data/', unzip=True)\n\n# Step 2: Data Preparation\nhr_df = pd.read_csv('data/aug_train.csv')\nfactory_df = pd.read_csv('data/Factory_Workers_Performance.csv')\n\n# Feature Engineering\ndef preprocess_data(df, dataset_type):\n    if dataset_type == 'hr':\n        df['role_context'] = df.apply(lambda x: f\"\"\"\n            Role: {x['enrollee_id']}, \n            Domain: {x['city']}, \n            Experience: {x['experience']} years, \n            Education: {x['education_level']}\n        \"\"\", axis=1)\n        return df[['role_context', 'target']]\n    else:\n        df['role_context'] = df.apply(lambda x: f\"\"\"\n            Role: {x['Position']}, \n            Department: {x['Department']}, \n            Tenure: {x['Tenure']} months, \n            Performance: {x['PerformanceRating']}\n        \"\"\", axis=1)\n        return df[['role_context', 'Attrition']]\n\nhr_processed = preprocess_data(hr_df, 'hr')\nfactory_processed = preprocess_data(factory_df, 'factory')\n\n# Step 3: Create Training Data with Change Management Context\nchange_contexts = {\n    'ADKAR': \"Individual skill development and phased adoption\",\n    'Kotter': \"Urgent organizational transformation\",\n    'Lewin': \"Behavioral pattern changes\",\n    'McKinsey': \"Structural realignment\"\n}\n\ndef create_training_examples(row):\n    examples = []\n    for model, context in change_contexts.items():\n        text = f\"\"\"\n        Role Context: {row['role_context']}\n        Change Type: {context}\n        Recommended Strategy: {model}\n        \"\"\"\n        examples.append(text)\n    return examples\n\n# Create training data\ntrain_data = []\nfor _, row in hr_processed.iterrows():\n    train_data.extend(create_training_examples(row))\nfor _, row in factory_processed.iterrows():\n    train_data.extend(create_training_examples(row))\n\n# Step 4: LLM Fine-Tuning\ntokenizer = AutoTokenizer.from_pretrained(\"microsoft/xtremedistil-l12-h384-uncased\")\nmodel = AutoModelForSequenceClassification.from_pretrained(\"microsoft/xtremedistil-l12-h384-uncased\", num_labels=4)\n\n# Prepare dataset\ntrain_texts, val_texts = train_test_split(train_data, test_size=0.2)\nlabels = [change_contexts.keys().index(text.split(\"Recommended Strategy: \")[-1].strip()) for text in train_texts]\n\nclass ChangeDataset(torch.utils.data.Dataset):\n    def __init__(self, texts, labels):\n        self.encodings = tokenizer(texts, padding=True, truncation=True, max_length=512)\n        self.labels = labels\n\n    def __getitem__(self, idx):\n        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n        item['labels'] = torch.tensor(self.labels[idx])\n        return item\n\n    def __len__(self):\n        return len(self.labels)\n\ntrain_dataset = ChangeDataset(train_texts, labels)\nval_dataset = ChangeDataset(val_texts, [change_contexts.keys().index(t.split(\"Recommended Strategy: \")[-1].strip()) for t in val_texts])\n\n# Training configuration\ntraining_args = TrainingArguments(\n    output_dir='./results',\n    num_train_epochs=3,\n    per_device_train_batch_size=8,\n    evaluation_strategy=\"epoch\"\n)\n\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=train_dataset,\n    eval_dataset=val_dataset\n)\n\n# Step 5: Model Training\ntrainer.train()\n\n# Step 6: Prediction Pipeline\ndef recommend_strategy(user_input):\n    role_part = user_input.split(\"Change:\")[0].replace(\"Role: \", \"\").strip()\n    change_part = user_input.split(\"Change:\")[1].strip()\n    \n    inputs = tokenizer(\n        f\"Role Context: {role_part}\\nChange Type: {change_part}\",\n        return_tensors=\"pt\",\n        padding=True,\n        truncation=True,\n        max_length=512\n    )\n    \n    outputs = model(**inputs)\n    predicted_idx = torch.argmax(outputs.logits).item()\n    return list(change_contexts.keys())[predicted_idx]\n\n# Example Usage\nuser_input = \"Role: Robotics Engineer with 5 years experience. Change: AI-Powered Quality Control Implementation\"\nprint(f\"Recommended Strategy: {recommend_strategy(user_input)}\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}